{"cells":[{"cell_type":"markdown","metadata":{"id":"y0kEuP8ptNd9"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGnQvYjA7adt"},"outputs":[],"source":["# 설치 후 런타임 재실행 \n","!pip install -U segmentation-models-pytorch albumentations --user\n","!pip install --user albumentations\n","!pip install opencv-contrib-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5AXNYhov7rNz"},"outputs":[],"source":["import albumentations \n","from albumentations.pytorch import ToTensorV2\n","from typing import List\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torchvision\n","from pathlib import Path\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import torchvision.transforms as T\n","import segmentation_models_pytorch as smp\n","import os\n","import torchvision.transforms.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from matplotlib import colors, pyplot as plt\n","%matplotlib inline\n","from PIL import Image\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"Z4T0K3FL9Agq"},"source":["## 1. 모델 정의 및 학습 \n","- 구글 마운트 후 사용하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHS--Nsv9D-1"},"outputs":[],"source":["# segmentation model - pytorch에서 제공\n","model = smp.Unet(\n","    encoder_name='resnext50_32x4d',\n","    classes=1,\n","    activation='sigmoid',\n","    encoder_weights='imagenet'\n",")"]},{"cell_type":"markdown","source":["손 - 이미지, 마스크"],"metadata":{"id":"7Y1aWv-vFRcb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OtB6m1Y49D8F"},"outputs":[],"source":["# 직접 찍은 손 사진 \n","dataset_dir = Path('/content/drive/MyDrive/4조/2.데이터')\n","hand_images_dir = dataset_dir / '손이미지'  # 직접 찍은 손 사진 \n","hand_masks_dir = dataset_dir / '손톱마스크' # 직접 만든 손 사진 마스크\n","\n","hand_images_lst = [filename for filename in os.listdir(hand_images_dir)]\n","hand_masks_lst = [filename for filename in os.listdir(hand_masks_dir)]\n","\n","len(hand_images_lst), len(hand_masks_lst)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-SB0CkWY9Dyu"},"outputs":[],"source":["# 마스크 이미지와 중복되는 데이터만 사용 \n","hand_images_n = [img for img in hand_images_lst if img in hand_masks_lst]\n","len(hand_images_n)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z52-h8w7AMMg"},"outputs":[],"source":["# images, masks = [], []\n","images = sorted([hand_images_dir / filename for filename in hand_images_n])\n","masks = sorted([hand_masks_dir / filename for filename in hand_images_n])\n","assert len(images) == len(masks)"]},{"cell_type":"markdown","source":["추가 손 데이터"],"metadata":{"id":"CNIK5adCKQ2i"}},{"cell_type":"code","source":["# 추가 데이터 \n","dataset_dir = Path('/content/drive/MyDrive/프포젝트/3_DDD/archive/nails_segmentation')\n","images_dir = dataset_dir / 'images'\n","masks_dir = dataset_dir / 'labels'\n","\n","images_add = sorted([images_dir / filename for filename in os.listdir(images_dir)])\n","masks_add  = sorted([masks_dir / filename for filename in os.listdir(masks_dir)])\n","\n","images.extend(images_add) \n","masks.extend(masks_add)"],"metadata":{"id":"0dCwDwbBIDj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["발 - 이미지, 마스크"],"metadata":{"id":"0V4x-sk2FWaX"}},{"cell_type":"code","source":["# 직접 찍은 발 사진 \n","dataset_dir = Path('/content/drive/MyDrive/4조/2.데이터')   # 발톱 사진\n","# my_dir = Path('/content/drive/MyDrive/프포젝트/3_DDD/data') # 밡톱마스크는 내 드라이브에\n","foot_images_dir = dataset_dir / '발이미지'  # 직접 찍은 발 사진 \n","foot_masks_dir = dataset_dir / '발톱마스크' # 직접 찍은 발 사진 마스크\n","\n","foot_images_lst = [filename for filename in os.listdir(foot_images_dir)]\n","foot_masks_lst = [filename for filename in os.listdir(foot_masks_dir)]\n","\n","len(foot_images_lst), len(foot_masks_lst)"],"metadata":{"id":"T_K6RYXRHAw-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 마스크 이미지와 중복되는 데이터만 사용 \n","foot_images_n = [img for img in foot_images_lst if img in foot_masks_lst]\n","len(foot_images_n)"],"metadata":{"id":"sFGz9Y4-H1yN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["foot_images_add = sorted([foot_images_dir / filename for filename in foot_images_n])\n","foot_masks_add  = sorted([foot_masks_dir / filename for filename in foot_images_n])\n","images.extend(foot_images_add) \n","masks.extend(foot_masks_add)"],"metadata":{"id":"PxdXHtA-I9wD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(images), len(masks)"],"metadata":{"id":"4sd2ItbkLExn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["train, test, val data split"],"metadata":{"id":"EWdU2Co6I3NM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIN_F1P0ATqE"},"outputs":[],"source":["# train, test, val data split\n","images_train, images_valid, masks_train, masks_valid = train_test_split(images, masks, train_size=0.7, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nj79_dB8AToO"},"outputs":[],"source":["class NailsDataset(torch.utils.data.Dataset):\n","    def __init__(self, images: List[str], masks: List[str], transform):\n","        self._images = images\n","        self._masks = masks\n","        self._transform = transform\n","        assert len(images) == len(masks)\n","  \n","    def __len__(self):\n","        return len(self._images)\n","  \n","    def __getitem__(self, index):\n","        image, mask = Image.open(self._images[index]), Image.open(self._masks[index]).convert('L')\n","        augmented = self._transform(image=np.array(image), mask=np.array(mask))\n","        image, mask = augmented['image'], augmented['mask']\n","        return image, mask[None].float() / 255"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YZip9T29ATmE"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4LcORvuFATj8"},"outputs":[],"source":["loss = smp.utils.losses.DiceLoss() + smp.utils.losses.BCELoss()\n","metrics = [smp.utils.metrics.IoU(threshold=0.47)]\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.005)\n","#lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2, eta_min=5e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_MB0gOcHATh3"},"outputs":[],"source":["trainepoch = smp.utils.train.TrainEpoch(\n","    model,\n","    loss=loss,\n","    optimizer=optimizer,\n","    metrics=metrics,\n","    device=device,\n","    verbose=True,\n",")\n","\n","validepoch = smp.utils.train.ValidEpoch(\n","    model,\n","    loss=loss,\n","    metrics=metrics,\n","    device=device,\n","    verbose=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Frm8n_SeApS_"},"outputs":[],"source":["epochs = 35\n","train_logs_list, valid_logs_list = [], []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sh3frtYZAwh_"},"outputs":[],"source":["max_score = 0\n","for epoch in range(epochs):\n","    print(f'Epoch: {epoch}')\n","    \n","    dataset_train = NailsDataset(\n","    images=images_train,\n","    masks=masks_train,\n","    transform=A.Compose([\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        A.RandomResizedCrop(height=224, width=224, scale=(0.7, 1)),\n","        A.Resize(224, 224),\n","        A.Flip(p=1),\n","        A.Rotate(limit=15, p=1),\n","        A.Sharpen(p=0.5),\n","        ToTensorV2(transpose_mask=True),\n","    ]),\n","    )\n","\n","    dataset_valid = NailsDataset(\n","        images=images_valid,\n","        masks=masks_valid,\n","        transform=A.Compose([\n","            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","            A.Resize(224, 224),\n","            ToTensorV2(transpose_mask=True),\n","        ]),\n","    )\n","    dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=4, shuffle=True)\n","    dataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=4, shuffle=True)\n","    \n","    trainlogs = trainepoch.run(dataloader_train)\n","    validlogs = validepoch.run(dataloader_valid)\n","\n","    train_logs_list.append(trainlogs)\n","    valid_logs_list.append(validlogs)\n","    \n","    if max_score < validlxfogs['iou_score']:\n","        max_score = validlogs['iou_score']\n","        torch.save(model, '/content/drive/MyDrive/4조/2.데이터/마스크 생성 모델/nail_foot_seg_best_model_2.pth')\n","        print('Model saved!')"]},{"cell_type":"markdown","source":["저장된 모델 불러와 결과 확인 \n"],"metadata":{"id":"9SFghob1LzhE"}},{"cell_type":"markdown","source":["모델2"],"metadata":{"id":"By9e72J3yd1c"}},{"cell_type":"code","source":["# 저장된 모델 불러오기\n","best_model = torch.load('/content/drive/MyDrive/4조/2.데이터/마스크 생성 모델/nail_foot_seg_best_model_2.pth') # pytorch model 확장자 .pth"],"metadata":{"id":"PZwmlSUHL78C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def iou(target, prediction):\n","    prediction = prediction\n","    intersection = np.logical_and(target, prediction)\n","    union = np.logical_or(target, prediction)\n","    iou_score = np.sum(intersection) / np.sum(union)\n","    return iou_score\n","\n","def iou2(target, prediction):\n","    tp = torch.sum(preds * y)  # TP\n","    fp = torch.sum(preds * (1 - y))  # FP\n","    fn = torch.sum((1 - preds) * y)  # FN\n","    tn = torch.sum((1 - preds) * (1 - y))  # TN\n","\n","    iou_score2 = (tp + 1e-8) / (tp + fp + fn + 1e-8)\n","    mean_acc = (tp + 1e-8)/(tp+fn + 1e-8)\n","    \n","    return iou_score2, mean_acc"],"metadata":{"id":"33LbGkoEMMCK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from skimage.filters import threshold_otsu\n","from torchvision.utils import draw_segmentation_masks\n","iou_score = 0\n","iou_score2 = 0\n","mean_acc = 0\n","otsu = 0\n","for imgs, masks in dataloader_valid:\n","    for img, mask in zip(imgs, masks):\n","        img = torch.unsqueeze(img, 0)  # torch.unsqueeze(): 1차원 제거 함수\n","        mask = torch.unsqueeze(mask, 0)\n","        \n","        fig, axes = plt.subplots(1, 3)\n","        pred = best_model((img).to(device))[0][0].cpu().detach().numpy() > 0.47\n","        preds = (best_model((img).to(device))[0][0].cpu().detach() > 0.47).float()\n","        y = (((mask).to(device))[0][0].cpu().detach()).float()\n","\n","        axes[0].imshow(pred)\n","        axes[0].set_title(\"Predicted mask\")\n","        axes[1].imshow(((mask).to(device))[0][0].cpu().detach().numpy())\n","        axes[1].set_title(\"Target mask\")\n","        axes[2].imshow(((img).to(device))[0][0].cpu().detach().numpy())\n","        axes[2].set_title(\"Target image\")\n","\n","        iou_score += iou(((mask).to(device))[0][0].cpu().detach().numpy(),pred)\n","        print(\"IoU\", iou(((mask).to(device))[0][0].cpu().detach().numpy(),pred))\n","\n","        otsu += threshold_otsu(best_model((img).to(device))[0][0].cpu().detach().numpy())\n","        iou_2, acc = iou2(((mask).to(device))[0][0].cpu().detach().numpy(),pred)\n","        iou_score2 += iou_2\n","        mean_acc += acc\n","\n","        fig.set_figwidth(12)   \n","        fig.set_figheight(6)  \n","        plt.show()\n","\n","iou_score = iou_score/len(dataset_valid)\n","iou_score2 = iou_score2/len(dataset_valid)\n","mean_acc = mean_acc/len(dataset_valid)\n","otsu = otsu/16\n","print(\"평균 IoU\", iou_score)\n","print(\"평균 IoU2\", iou_score2.item())\n","print(\"mean accuracy\", mean_acc.item())\n","print(otsu)"],"metadata":{"id":"OhbTPZPg6WRr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델1\n"],"metadata":{"id":"CEMZU03gyimh"}},{"cell_type":"code","source":["best_model = torch.load('/content/drive/MyDrive/프포젝트/3_DDD/data/nail_foot_seg_best_model.pth') # pytorch model 확장자 .pth\n","\n","from skimage.filters import threshold_otsu\n","from torchvision.utils import draw_segmentation_masks\n","iou_score = 0\n","iou_score2 = 0\n","mean_acc = 0\n","otsu = 0\n","for imgs, masks in dataloader_valid:\n","    for img, mask in zip(imgs, masks):\n","        img = torch.unsqueeze(img, 0)  # torch.unsqueeze(): 1차원 제거 함수\n","        mask = torch.unsqueeze(mask, 0)\n","        \n","        fig, axes = plt.subplots(1, 3)\n","        pred = best_model((img).to(device))[0][0].cpu().detach().numpy() > 0.47\n","        preds = (best_model((img).to(device))[0][0].cpu().detach() > 0.47).float()\n","        y = (((mask).to(device))[0][0].cpu().detach()).float()\n","\n","        axes[0].imshow(pred)\n","        axes[0].set_title(\"Predicted mask\")\n","        axes[1].imshow(((mask).to(device))[0][0].cpu().detach().numpy())\n","        axes[1].set_title(\"Target mask\")\n","        axes[2].imshow(((img).to(device))[0][0].cpu().detach().numpy())\n","        axes[2].set_title(\"Target image\")\n","\n","        iou_score += iou(((mask).to(device))[0][0].cpu().detach().numpy(),pred)\n","        print(\"IoU\", iou(((mask).to(device))[0][0].cpu().detach().numpy(),pred))\n","\n","        otsu += threshold_otsu(best_model((img).to(device))[0][0].cpu().detach().numpy())\n","        iou_2, acc = iou2(((mask).to(device))[0][0].cpu().detach().numpy(),pred)\n","        iou_score2 += iou_2\n","        mean_acc += acc\n","\n","        fig.set_figwidth(12)   \n","        fig.set_figheight(6)  \n","        plt.show()\n","\n","iou_score = iou_score/len(dataset_valid)\n","iou_score2 = iou_score2/len(dataset_valid)\n","mean_acc = mean_acc/len(dataset_valid)\n","otsu = otsu/16\n","print(\"평균 IoU\", iou_score)\n","print(\"평균 IoU2\", iou_score2.item())\n","print(\"mean accuracy\", mean_acc.item())\n","print(otsu)"],"metadata":{"id":"bW51-H7dyba0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. 마스크 없는 사진으로 테스트\n","- 저장된 모델 불러와서 사용하기"],"metadata":{"id":"QbJ-zsfFMb3R"}},{"cell_type":"code","source":["# 저장된 모델 불러오기\n","# 사용시 경로 변경 후 사용!\n","best_model = torch.load('/content/drive/MyDrive/프포젝트/3_DDD/data/nail_foot_seg_best_model.pth') # pytorch model 확장자 .pth"],"metadata":{"id":"ba4BE3FHMz8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 불러오기 \n","test_dataset_dir = Path('/content/drive/MyDrive/4조/2.데이터')\n","test_hand_images_dir = test_dataset_dir / '손이미지'\n","test_foot_images_dir = test_dataset_dir / '발이미지'\n","\n","test_hand_images = sorted([test_hand_images_dir / filename for filename in os.listdir(test_hand_images_dir)])\n","test_foot_images = sorted([test_foot_images_dir / filename for filename in os.listdir(test_foot_images_dir)])"],"metadata":{"id":"7k6BKwhXMvub"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","img = cv2.imread(\"/content/drive/MyDrive/4조/2.데이터/손이미지/손_0.jpg\")\n","img.shape"],"metadata":{"id":"LOZ4Qct7S1Ig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_hand_images), len(test_foot_images)"],"metadata":{"id":"E37KimPEGzWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_hand_images[0]"],"metadata":{"id":"56bwg4UZ_rlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class test_NailsDataset(torch.utils.data.Dataset):\n","    def __init__(self, images: List[str], transform):\n","        self._images = images\n","        # self._masks = masks\n","        self._transform = transform\n","        # assert len(images) == len(masks)\n","  \n","    def __len__(self):\n","        return len(self._images)\n","  \n","    def __getitem__(self, index):\n","        image = Image.open(self._images[index])\n","        augmented = self._transform(image=np.array(image))\n","        image= augmented['image']\n","        return image"],"metadata":{"id":"SYPV4LHyOkPv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["손 이미지"],"metadata":{"id":"_GEEIBoH_ig2"}},{"cell_type":"code","source":["test_dataset = test_NailsDataset(\n","    images=test_hand_images,\n","    transform=A.Compose([\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        A.Resize(height= 224 ,width= 224),\n","        # A.RandomResizedCrop(height=224, width=224, scale=(0.7, 1)),\n","        # A.Flip(p=1),\n","        # A.Rotate(limit=15, p=1),\n","        A.Sharpen(p=0.5),\n","        ToTensorV2(transpose_mask=True),\n","    ]),\n","    )\n","\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1 ,shuffle=False)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"r1C_PqNsOxKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(test_dataset) ,len(test_dataloader)"],"metadata":{"id":"w-s_TmqMHQ1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def inverse_normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n","#     \"\"\"\n","#     :param img: numpy array. shape (height, width, channel). [-1~1]\n","#     :return: numpy array. shape (height, width, channel). [0~1]\n","#     \"\"\"\n","#     img[:,:,0] = ((img[:,:,0]) * std[0]) + mean[0]\n","#     img[:,:,1] = ((img[:,:,1]) * std[1]) + mean[1]\n","#     img[:,:,2] = ((img[:,:,2]) * std[2]) + mean[2]\n","#     return img"],"metadata":{"id":"ScIXaJPHYcAy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### TEST DATA ###\n","# score 표시 X\n","from skimage.filters import threshold_otsu\n","from torchvision.utils import draw_segmentation_masks\n","from tqdm import tqdm\n","from PIL import Image\n","\n","iou_score = 0\n","iou_score2 = 0\n","mean_acc = 0\n","otsu = 0\n","\n","for i, imgs in tqdm(enumerate(test_dataloader)):\n","    for img in imgs:\n","      \n","        img = torch.unsqueeze(img, 0)  # torch.unsqueeze(): 1차원 제거 함수\n","        pred = best_model((img).to(device))[0][0].cpu().detach().numpy() > 0.47  \n","        preds = (best_model((img).to(device))[0][0].cpu().detach() > 0.47).float()\n","        # y = (((mask).to(device))[0][0].cpu().detach()).float()\n","\n","        # 시각화 \n","        fig, axes = plt.subplots(1, 2)\n","        axes[0].imshow(pred)\n","        axes[0].set_title(\"Predicted mask\")\n","\n","        # axes[1].imshow(((img).to(device))[0][0].cpu().detach().numpy())\n","        img_o = ((img).to(device))[0][0].cpu().detach().numpy()\n","        axes[1].imshow(img_o)\n","        axes[1].set_title(\"Target image\")\n","\n","        otsu += threshold_otsu(best_model((img).to(device))[0][0].cpu().detach().numpy())\n","        fig.set_figwidth(12)   \n","        fig.set_figheight(6)  \n","        plt.show()\n","        \n","        # img_og = cv2.cvtColor(np.array(img_o), cv2.COLOR_BGR2RGB)\n","        # PIL.Image.fromarray(img[0].cpu().numpy(), 'RGB').save(f'{outdir}/seed{seed:04d}.png')\n","        # image = Image.fromarray(np.uint8(cm.plasma(image_array)*255))\n","        # Image.fromarray(np.uint8(cm.plasma(img_o)*255)).save(f'/content/drive/MyDrive/4조/2.데이터/모델_손발마스크/손/손_원본/원본_손_{i}.jpg')\n","        \n","        # plt.imsave( f'/content/drive/MyDrive/4조/2.데이터/모델_손발마스크/손/손_원본/원본_손_{i}.jpg', img_og)\n","        plt.imsave( f'/content/drive/MyDrive/4조/2.데이터/모델_손발마스크/손/모델마스크_손_{i}.jpg', pred, cmap='gray')\n","\n"],"metadata":{"id":"RnMfA6SwMeH7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["발 이미지"],"metadata":{"id":"DrgAyo8UBnmy"}},{"cell_type":"code","source":["test_dataset = test_NailsDataset(\n","    images=test_foot_images,\n","    transform=A.Compose([\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        A.Resize(height= 224 ,width= 224),\n","        A.Sharpen(p=0.5),\n","        ToTensorV2(transpose_mask=True),\n","    ]),\n","    )\n","\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"1b5a0Dg8oux7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### TEST DATA ###\n","# score 표시 X\n","from skimage.filters import threshold_otsu\n","from torchvision.utils import draw_segmentation_masks\n","from tqdm import tqdm\n","\n","iou_score = 0\n","iou_score2 = 0\n","mean_acc = 0\n","otsu = 0\n","\n","test_imgs_lst, test_preds_lst = [], [] # 원본 이미지, 마스크 이미지 담을 리스트 \n","\n","for i, imgs in tqdm(enumerate(test_dataloader)):\n","    for img in imgs:\n","      \n","        img = torch.unsqueeze(img, 0)  # torch.unsqueeze(): 1차원 제거 함수\n","        pred = best_model((img).to(device))[0][0].cpu().detach().numpy() > 0.47  \n","        preds = (best_model((img).to(device))[0][0].cpu().detach() > 0.47).float()\n","        # y = (((mask).to(device))[0][0].cpu().detach()).float()\n","\n","        test_imgs_lst.append(img)\n","        test_preds_lst.append(preds)\n","\n","        # 시각화 \n","        fig, axes = plt.subplots(1, 2)\n","        axes[0].imshow(pred)\n","        axes[0].set_title(\"Predicted mask\")\n","        axes[1].imshow(((img).to(device))[0][0].cpu().detach().numpy())\n","        axes[1].set_title(\"Target image\")\n","\n","        otsu += threshold_otsu(best_model((img).to(device))[0][0].cpu().detach().numpy())\n","        fig.set_figwidth(12)   \n","        fig.set_figheight(6)  \n","        plt.show()\n","        \n","        # 사진 저장\n","        plt.imsave( f'/content/drive/MyDrive/4조/2.데이터/모델_손발마스크/발/모델마스크_발_{i}.jpg', pred, cmap='gray')"],"metadata":{"id":"Nzz076xyCkCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"PO2CNmKvDj_T"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"0719_nail-foot-mask_pytorch_UNET_2.ipynb의 사본","provenance":[],"machine_shape":"hm","private_outputs":true,"background_execution":"on","mount_file_id":"1FVtgBTK7zPErp9YwjpRzMiqvHR2pUyQV","authorship_tag":"ABX9TyO7FttZuNPxePl5x6HVAgd9"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}